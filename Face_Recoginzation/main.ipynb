{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "# from google.colab import drive\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# # Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "VIDEO_PATH = \"./test/fan__official_trailer__shah_rukh_khan.mp3\"\n",
    "OUTPUT_VIDEO_PATH = \"./test/fan__official_trailer__shah_rukh_khan_2.mp3\"\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    # Load all known faces from the directory\n",
    "    for filename in os.listdir(known_image_dir):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(known_image_dir, filename)\n",
    "            name = os.path.splitext(filename)[0]  # Extract name from filename\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            if face_encodings:\n",
    "                known_face_encodings.append(face_encodings[0])\n",
    "                known_face_names.append(name)\n",
    "                print(f\"Loaded {name} from {filename}\")\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "def recognize_faces_in_video(video_path, known_face_encodings, known_face_names, output_video_path):\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Define codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # or 'XVID' for AVI\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR (OpenCV format) to RGB (face_recognition format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all the faces and face encodings in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Loop over each face found in the frame\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # See if the face is a match for any of the known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with the name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        # Write the frame into the output video\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release everything when the job is finished\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load known faces from the specified directory\n",
    "    known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "\n",
    "    # Process video and save output\n",
    "    recognize_faces_in_video(VIDEO_PATH, known_face_encodings, known_face_names, OUTPUT_VIDEO_PATH)\n",
    "\n",
    "    # Display the result\n",
    "    print(\"Video processing complete. Output video saved to Google Drive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Ibtasam from Ibtasam.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m known_face_encodings, known_face_names \u001b[38;5;241m=\u001b[39m load_known_faces(KNOWN_IMAGE_DIR)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Process webcam feed and save output\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[43mrecognize_faces_in_webcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_face_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_VIDEO_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebcam processing complete. Output video saved to folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m, in \u001b[0;36mrecognize_faces_in_webcam\u001b[1;34m(known_face_encodings, known_face_names, output_video_path)\u001b[0m\n\u001b[0;32m     43\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Find all the faces and face encodings in the frame\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_frame, face_locations)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Loop over each face found in the frame\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "OUTPUT_VIDEO_PATH = \"./test/Shahrukh_Khan_Hairstyle.jpeg\"\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for filename in os.listdir(known_image_dir):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(known_image_dir, filename)\n",
    "            name = os.path.splitext(filename)[0]  \n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            if face_encodings:\n",
    "                known_face_encodings.append(face_encodings[0])\n",
    "                known_face_names.append(name)\n",
    "                print(f\"Loaded {name} from {filename}\")\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "def recognize_faces_in_webcam(known_face_encodings, known_face_names, output_video_path):\n",
    "    video_capture = cv2.VideoCapture(0)  \n",
    "\n",
    "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = 20.0  # Adjust FPS if needed\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID' for AVI\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR (OpenCV format) to RGB (face_recognition format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all the faces and face encodings in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Loop over each face found in the frame\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # See if the face is a match for any of the known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with the name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Webcam Feed', frame)\n",
    "\n",
    "        # Break loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load known faces from the specified directory\n",
    "    known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "\n",
    "    # Process webcam feed and save output\n",
    "    recognize_faces_in_webcam(known_face_encodings, known_face_names, OUTPUT_VIDEO_PATH)\n",
    "\n",
    "    # Display the result\n",
    "    print(\"Webcam processing complete. Output video saved to folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Processing a Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot identify image file Shahrukh.jpg. Skipping.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import UnidentifiedImageError, Image\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "UNKNOWN_IMAGE_DIR = \"./unknown_images\"\n",
    "VIDEO_PATH = \"fan__official_trailer__shah_rukh_khan.mp3\"  # Replace with your video file path\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for filename in os.listdir(known_image_dir):\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(known_image_dir, filename)\n",
    "            name = os.path.splitext(filename)[0]\n",
    "\n",
    "            try:\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "                if face_encodings:\n",
    "                    known_face_encodings.append(face_encodings[0])\n",
    "                    known_face_names.append(name)\n",
    "                else:\n",
    "                    print(f\"No face found in {filename}. Skipping.\")\n",
    "\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Cannot identify image file {filename}. Skipping.\")\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "def recognize_faces_in_video(known_face_encodings, known_face_names, video_path, unknown_image_dir):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not os.path.exists(unknown_image_dir):\n",
    "        os.makedirs(unknown_image_dir)\n",
    "\n",
    "    while video_capture.isOpened():\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True not in matches:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                unknown_image_path = os.path.join(unknown_image_dir, f\"unknown_{timestamp}.jpg\")\n",
    "                cv2.imwrite(unknown_image_path, frame)\n",
    "            else:\n",
    "                best_match_index = matches.index(True)\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Video Feed', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "    recognize_faces_in_video(known_face_encodings, known_face_names, VIDEO_PATH, UNKNOWN_IMAGE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Real-Time Webcam Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file './test\\\\Shahrukh.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 68\u001b[0m     known_face_encodings, known_face_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_known_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKNOWN_IMAGE_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     recognize_faces_in_webcam(known_face_encodings, known_face_names, UNKNOWN_IMAGE_DIR)\n",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mload_known_faces\u001b[1;34m(known_image_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(known_image_dir, filename)\n\u001b[0;32m     16\u001b[0m name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(filename)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(image)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m face_encodings:\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:86\u001b[0m, in \u001b[0;36mload_image_file\u001b[1;34m(file, mode)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image_file\u001b[39m(file, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    Loads an image file (.jpg, .png, etc) into a numpy array\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    :return: image contents as numpy array\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode:\n\u001b[0;32m     88\u001b[0m         im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mconvert(mode)\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\PIL\\Image.py:3283\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3281\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3282\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3283\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file './test\\\\Shahrukh.jpg'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import UnidentifiedImageError, Image\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "UNKNOWN_IMAGE_DIR = \"./unknown_images\"\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for filename in os.listdir(known_image_dir):\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(known_image_dir, filename)\n",
    "            name = os.path.splitext(filename)[0]\n",
    "\n",
    "            try:\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "                if face_encodings:\n",
    "                    known_face_encodings.append(face_encodings[0])\n",
    "                    known_face_names.append(name)\n",
    "                else:\n",
    "                    print(f\"No face found in {filename}. Skipping.\")\n",
    "\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Cannot identify image file {filename}. Skipping.\")\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "def recognize_faces_in_webcam(known_face_encodings, known_face_names, unknown_image_dir):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    if not os.path.exists(unknown_image_dir):\n",
    "        os.makedirs(unknown_image_dir)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True not in matches:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                unknown_image_path = os.path.join(unknown_image_dir, f\"unknown_{timestamp}.jpg\")\n",
    "                cv2.imwrite(unknown_image_path, frame)\n",
    "            else:\n",
    "                best_match_index = matches.index(True)\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Webcam Feed', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "    recognize_faces_in_webcam(known_face_encodings, known_face_names, UNKNOWN_IMAGE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Ibtasam from Ibtasam.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163143.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163149.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163151.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163153.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163154.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163156.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_163158.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m known_face_encodings, known_face_names \u001b[38;5;241m=\u001b[39m load_known_faces(KNOWN_IMAGE_DIR)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Process webcam feed and save output\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[43mrecognize_faces_in_webcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_face_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_VIDEO_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebcam processing complete. Output video saved to folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m, in \u001b[0;36mrecognize_faces_in_webcam\u001b[1;34m(known_face_encodings, known_face_names, output_video_path)\u001b[0m\n\u001b[0;32m     62\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Find all the faces and face encodings in the frame\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_frame, face_locations)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Loop over each face found in the frame\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "OUTPUT_VIDEO_PATH = \"./test/Shahrukh_Khan_Hairstyle.jpeg\"\n",
    "UNKNOWN_IMAGE_DIR = \"./picture\"  # Directory to save images of unknown faces\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for filename in os.listdir(known_image_dir):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(known_image_dir, filename)\n",
    "            name = os.path.splitext(filename)[0]  \n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            if face_encodings:\n",
    "                known_face_encodings.append(face_encodings[0])\n",
    "                known_face_names.append(name)\n",
    "                print(f\"Loaded {name} from {filename}\")\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "def save_unknown_face(frame, face_location):\n",
    "    # Ensure the unknown image directory exists\n",
    "    os.makedirs(UNKNOWN_IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "    # Extract the face region\n",
    "    top, right, bottom, left = face_location\n",
    "    face_image = frame[top:bottom, left:right]\n",
    "\n",
    "    # Create a unique filename with a timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"unknown_{timestamp}.jpg\"\n",
    "    filepath = os.path.join(UNKNOWN_IMAGE_DIR, filename)\n",
    "\n",
    "    # Save the face image\n",
    "    cv2.imwrite(filepath, face_image)\n",
    "    print(f\"Saved unknown face to {filepath}\")\n",
    "\n",
    "def recognize_faces_in_webcam(known_face_encodings, known_face_names, output_video_path):\n",
    "    video_capture = cv2.VideoCapture(0)  \n",
    "\n",
    "    frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = 20.0  # Adjust FPS if needed\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID' for AVI\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR (OpenCV format) to RGB (face_recognition format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all the faces and face encodings in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Loop over each face found in the frame\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # See if the face is a match for any of the known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "            else:\n",
    "                save_unknown_face(frame, (top, right, bottom, left))  # Save screenshot of unknown face\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with the name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Webcam Feed', frame)\n",
    "\n",
    "        # Break loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load known faces from the specified directory\n",
    "    known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "\n",
    "    # Process webcam feed and save output\n",
    "    recognize_faces_in_webcam(known_face_encodings, known_face_names, OUTPUT_VIDEO_PATH)\n",
    "\n",
    "    # Display the result\n",
    "    print(\"Webcam processing complete. Output video saved to folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Ibtasam from Ibtasam.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173930.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173940.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173942.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173942.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173944.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173946.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173947.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173948.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173953.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173956.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_173957.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174000.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174000.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174002.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174003.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174006.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174006.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174008.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174008.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174011.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174011.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174014.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_174014.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m known_face_encodings, known_face_names \u001b[38;5;241m=\u001b[39m load_known_faces(KNOWN_IMAGE_DIR)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Process webcam feed and save output\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[43mrecognize_faces_in_webcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_face_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebcam processing complete. Output video saved to folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m, in \u001b[0;36mrecognize_faces_in_webcam\u001b[1;34m(known_face_encodings, known_face_names)\u001b[0m\n\u001b[0;32m     60\u001b[0m rgb_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Find all the faces and face encodings in the frame\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_frame, face_locations)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Loop over each face found in the frame\u001b[39;00m\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "UNKNOWN_IMAGE_DIR = \"./picture\"  # Directory to save images of unknown faces\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "  known_face_encodings = []\n",
    "  known_face_names = []\n",
    "\n",
    "  for filename in os.listdir(known_image_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "      image_path = os.path.join(known_image_dir, filename)\n",
    "      name = os.path.splitext(filename)[0]\n",
    "      image = face_recognition.load_image_file(image_path)\n",
    "      face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "      if face_encodings:\n",
    "        known_face_encodings.append(face_encodings[0])\n",
    "        known_face_names.append(name)\n",
    "        print(f\"Loaded {name} from {filename}\")\n",
    "\n",
    "  return known_face_encodings, known_face_names\n",
    "\n",
    "def save_unknown_face(frame, face_location):\n",
    "  # Ensure the unknown image directory exists\n",
    "  os.makedirs(UNKNOWN_IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "  # Extract the face region\n",
    "  top, right, bottom, left = face_location\n",
    "  face_image = frame[top:bottom, left:right]\n",
    "\n",
    "  # Create a unique filename with a timestamp\n",
    "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  filename = f\"unknown_{timestamp}.jpg\"\n",
    "  filepath = os.path.join(UNKNOWN_IMAGE_DIR, filename)\n",
    "\n",
    "  # Save the face image\n",
    "  cv2.imwrite(filepath, face_image)\n",
    "  print(f\"Saved unknown face to {filepath}\")\n",
    "\n",
    "def recognize_faces_in_webcam(known_face_encodings, known_face_names):\n",
    "  video_capture = cv2.VideoCapture(0)  \n",
    "\n",
    "  frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "  frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "  fps = 20.0  # Adjust FPS if needed\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID' for AVI\n",
    "\n",
    "  while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "      print(\"Failed to grab frame\")\n",
    "      break\n",
    "\n",
    "    # Convert the image from BGR (OpenCV format) to RGB (face_recognition format)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find all the faces and face encodings in the frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    # Loop over each face found in the frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "      # See if the face is a match for any of the known faces\n",
    "      matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "      name = \"Unknown\"\n",
    "\n",
    "      # Use the known face with the smallest distance to the new face\n",
    "      face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "      best_match_index = face_distances.argmin()\n",
    "      if matches[best_match_index]:\n",
    "        name = known_face_names[best_match_index]\n",
    "      else:\n",
    "        save_unknown_face(frame, (top, right, bottom, left))  # Save screenshot of unknown face\n",
    "\n",
    "      # Draw a rectangle around the face\n",
    "      cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "      # Draw a label with the name below the face\n",
    "      cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "      font = cv2.FONT_HERSHEY_DUPLEX\n",
    "      cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Webcam Feed', frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "  video_capture.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # Load known faces from the specified directory\n",
    "  known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "\n",
    "  # Process webcam feed and save output\n",
    "  recognize_faces_in_webcam(known_face_encodings, known_face_names)\n",
    "\n",
    "  # Display the result\n",
    "  print(\"Webcam processing complete. Output video saved to folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Ibtasam from Ibtasam.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_192819.jpg\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Saved unknown face to ./picture\\unknown_20240831_192822.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_192823.jpg\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Saved unknown face to ./picture\\unknown_20240831_192837.jpg\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Saved unknown face to ./picture\\unknown_20240831_192922.jpg\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Please be one person in front of the camera\n",
      "Saved unknown face to ./picture\\unknown_20240831_192934.jpg\n",
      "Saved unknown face to ./picture\\unknown_20240831_192935.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m known_face_encodings, known_face_names \u001b[38;5;241m=\u001b[39m load_known_faces(KNOWN_IMAGE_DIR)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Process webcam feed and save output\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[43mrecognize_faces_in_webcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_face_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_face_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Display the result\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWebcam processing complete. Output video saved to folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m, in \u001b[0;36mrecognize_faces_in_webcam\u001b[1;34m(known_face_encodings, known_face_names)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Find all the faces and face encodings in the frame\u001b[39;00m\n\u001b[0;32m     58\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(rgb_frame)\n\u001b[1;32m---> 59\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Check the number of faces detected\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_locations) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[1;32me:\\AI Projects\\Face_Recoginzation\\virtualenv\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_face_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_landmark_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_jitters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "KNOWN_IMAGE_DIR = \"./test\"\n",
    "UNKNOWN_IMAGE_DIR = \"./picture\"  # Directory to save images of unknown faces\n",
    "\n",
    "def load_known_faces(known_image_dir):\n",
    "  known_face_encodings = []\n",
    "  known_face_names = []\n",
    "\n",
    "  for filename in os.listdir(known_image_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "      image_path = os.path.join(known_image_dir, filename)\n",
    "      name = os.path.splitext(filename)[0]\n",
    "      image = face_recognition.load_image_file(image_path)\n",
    "      face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "      if face_encodings:\n",
    "        known_face_encodings.append(face_encodings[0])\n",
    "        known_face_names.append(name)\n",
    "        print(f\"Loaded {name} from {filename}\")\n",
    "\n",
    "  return known_face_encodings, known_face_names\n",
    "\n",
    "def save_unknown_face(frame, face_location):\n",
    "  # Ensure the unknown image directory exists\n",
    "  os.makedirs(UNKNOWN_IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "  # Extract the face region\n",
    "  top, right, bottom, left = face_location\n",
    "  face_image = frame[top:bottom, left:right]\n",
    "\n",
    "  # Create a unique filename with a timestamp\n",
    "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  filename = f\"unknown_{timestamp}.jpg\"\n",
    "  filepath = os.path.join(UNKNOWN_IMAGE_DIR, filename)\n",
    "\n",
    "  # Save the face image\n",
    "  cv2.imwrite(filepath, face_image)\n",
    "  print(f\"Saved unknown face to {filepath}\")\n",
    "\n",
    "def recognize_faces_in_webcam(known_face_encodings, known_face_names):\n",
    "    video_capture = cv2.VideoCapture(0)  \n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the image from BGR (OpenCV format) to RGB (face_recognition format)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all the faces and face encodings in the frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Check the number of faces detected\n",
    "        if len(face_locations) != 1:\n",
    "            print(\"Please be one person in front of the camera\")\n",
    "            cv2.imshow('Webcam Feed', frame)\n",
    "        else:\n",
    "            # Loop over each face found in the frame\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                # See if the face is a match for any of the known faces\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # Use the known face with the smallest distance to the new face\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = face_distances.argmin()\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                else:\n",
    "                    save_unknown_face(frame, (top, right, bottom, left))  # Save screenshot of unknown face\n",
    "\n",
    "                # Draw a rectangle around the face\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "                # Draw a label with the name below the face\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            cv2.imshow('Webcam Feed', frame)\n",
    "\n",
    "        # Break loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # Load known faces from the specified directory\n",
    "  known_face_encodings, known_face_names = load_known_faces(KNOWN_IMAGE_DIR)\n",
    "\n",
    "  # Process webcam feed and save output\n",
    "  recognize_faces_in_webcam(known_face_encodings, known_face_names)\n",
    "\n",
    "  # Display the result\n",
    "  print(\"Webcam processing complete. Output video saved to folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
