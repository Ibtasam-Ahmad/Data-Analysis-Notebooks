{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's be investigators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have access to a communication network of a famous company involved in one of the largest economical scandals: enron email dataset. \n",
    "\n",
    "The goal: using all the measures and quantities we have seen so far analyse the network. Who are the most central nodes? How the different ranks compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# the data is in \"data/email-Enron.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# as usual we need to import the key libraries we need to store, analyse and plot the network\n",
    "import networkx as nx\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Setup and Data Loading:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2']\n",
      "['2', '3']\n",
      "['3', '1']\n",
      "['2', '4']\n",
      "['1', '4']\n",
      "['1', '5']\n",
      "['2', '5']\n",
      "['3', '5']\n",
      "['5', '6']\n",
      "['6', '7']\n",
      "['6', '8']\n",
      "['6', '9']\n",
      "['7', '8']\n",
      "['7', '9']\n",
      "['9', '10']\n",
      "['6', '11']\n",
      "['11', '12']\n",
      "['11', '13']\n",
      "['11', '14']\n",
      "['12', '15']\n",
      "['13', '14']\n",
      "['12', '13']\n"
     ]
    }
   ],
   "source": [
    "# let's also get a network from the folder \"data\"\n",
    "a=open(\"data/net1_edge_list.txt\",\"r\")\n",
    "for i in a:\n",
    "    n=i.strip().split()\n",
    "    print (n)\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2cfbe7270a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Enron email dataset\n",
    "G = nx.Graph()\n",
    "with open(\"data/email-Enron.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        nodes = line.strip().split()\n",
    "        G.add_edge(nodes[0], nodes[1])\n",
    "\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plotting the Network:**\n",
    "\n",
    "We can visualize the network to get an initial understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, pos=nx.spring_layout(G), alpha=0.9, node_size=10, width=0.3, edge_color=\"Black\", node_color=\"Red\", with_labels=True, font_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Degree Centrality:**\n",
    "\n",
    "Calculate and rank nodes by degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = sorted([[G.degree(n), n] for n in G.nodes()], reverse=True)\n",
    "for i in range(10):\n",
    "    print(f\"Rank = {i+1}, Degree = {degree[i][0]}, Node id = {degree[i][1]}\")\n",
    "\n",
    "# Save to CSV\n",
    "with open('data/Degree Centrality.csv', 'w') as f:\n",
    "    f.write(\"Rank,Degree,Node id\\n\")\n",
    "    for i in range(len(degree)):\n",
    "     f.write(f\"{i+1},{degree[i][0]},{degree[i][1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Closeness Centrality:**\n",
    "\n",
    "Calculate and rank nodes by closeness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness = sorted([[nx.closeness_centrality(G)[n], n] for n in G.nodes()], reverse=True)\n",
    "for i in range(10):\n",
    "    print(f\"Rank = {i+1}, Closeness = {closeness[i][0]:.2f}, Node id = {closeness[i][1]}\")\n",
    "\n",
    "# Save to CSV\n",
    "with open('data/Closeness Centrality.csv', 'w') as f:\n",
    "    f.write(\"Rank,Closeness,Node id\\n\")\n",
    "    for i in range(len(closeness)):\n",
    "        f.write(f\"{i+1},{closeness[i][0]:.2f},{closeness[i][1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Betweenness Centrality:**\n",
    "\n",
    "Calculate and rank nodes by betweenness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = sorted([[nx.betweenness_centrality(G)[n], n] for n in G.nodes()], reverse=True)\n",
    "for i in range(10):\n",
    "    print(f\"Rank = {i+1}, Betweenness = {betweenness[i][0]:.2f}, Node id = {betweenness[i][1]}\")\n",
    "\n",
    "# Save to CSV\n",
    "with open('data/Betweenness Centrality.csv', 'w') as f:\n",
    "    f.write(\"Rank,Betweenness,Node id\\n\")\n",
    "    for i in range(len(betweenness)):\n",
    "        f.write(f\"{i+1},{betweenness[i][0]:.2f},{betweenness[i][1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Eigenvector Centrality:**\n",
    "\n",
    "Calculate and rank nodes by eigenvector centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector = sorted([[nx.eigenvector_centrality(G)[n], n] for n in G.nodes()], reverse=True)\n",
    "for i in range(10):\n",
    "    print(f\"Rank = {i+1}, Eigenvector Cent. = {eigenvector[i][0]:.2f}, Node id = {eigenvector[i][1]}\")\n",
    "\n",
    "# Save to CSV\n",
    "with open('data/Eigenvector Centrality.csv', 'w') as f:\n",
    "    f.write(\"Rank,Eigenvector,Node id\\n\")\n",
    "    for i in range(len(eigenvector)):\n",
    "        f.write(f\"{i+1},{eigenvector[i][0]:.2f},{eigenvector[i][1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing the Enron email dataset using these centrality measures, we can identify the most central individuals in the network. Comparing the ranks across different centralities can provide insights into the roles and importance of these nodes.\n",
    "\n",
    "* Degree Centrality: Highlights nodes with the most connections.\n",
    "* Closeness Centrality: Identifies nodes that can quickly reach other nodes.\n",
    "* Betweenness Centrality: Finds nodes that act as bridges in the network.\n",
    "* Eigenvector Centrality: Measures the influence of nodes based on their connections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
